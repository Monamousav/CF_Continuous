---
title: "Estimation of the effect of a continuous treatment variable"
format:
  html: default
execute:
  echo: false
bibliography: references.bib
---

```{r}
#| include: false
library(data.table)
library(dplyr)
library(flextable)
library(officer)
```

# Introduction

+ Background
+ Why we need the methods we are proposing? Motivation.
+ Summary of findings 

# Method

We run Monte Carlo simulation to test the performance of ...

## Data generation


## Models and estimation procedures

<span style = "color: blue;"> Use math here to explain orthogonalization. This is where you explain what SO and DO in general. The sections below add specifics to the individual approaches we take. You also need to provide contexts (past studies). </span>


The standard approach in the precision-agriculture literature for estimating site-specific input response is to model the outcome level directly as a function of the treatment/input and covariates—e.g., estimate $Y=f(I,C)$ where $I$ is the input (like nitrogen rate) and $C$ are field characteristics—and then derive optimal input decisions from that estimated function. This is what is typically done in the recent on-farm precision experimentation literature (e.g., @barbosa2020risk; @barbosa2020modeling; @krause2020random; @gardner2021economic).
The problem is that these methods optimize prediction of yield levels—not the causal effect of changing the input. Good level prediction at the observed input does not guarantee accurate recovery of the response function needed for optimal input choice, because the fitted $f(I,C)$ can conflate input variation with confounding and misattribute the drivers of yield variation.

To identify causal effects rather than just predict levels in the single binary treatment case, researchers use double/debiased machine learning (DML), which introduces orthogonalization so the treatment-effect estimator is insensitive to small errors in the auxiliary fits (I need citation here). 
Consider the structural model (Model 1):

```{=tex}
\begin{align*}
Y=\theta(X) T+g(X, W)+v
\end{align*}
```

where $Y$ is the outcome, $T \in\{0,1\}$  is the treatment, $X$ covariates that also modify the treatment effect $\theta(X)$, $W$ additional predictors of $Y$, and $v$ is noise. 
Orthogonalization estimates $f(X, W)=\mathbb{E}[Y \mid X, W]$ and $h(X, W)=\mathbb{E}[T \mid X, W]$, forms residuals $Y_{\mathrm{res}}=Y-f(X,W)$ and $T_{\mathrm{res}}=T-h(X, W)$, and then relates $Y_{\mathrm{res}}$ to $T_{\mathrm{res}}$. Because this score is Neyman-orthogonal and is typically implemented with cross-fitting, small errors in $f$ and $h$ do not induce first-order bias in $\theta(X)$.

The identifying algebra in Model 1 follows from linearity in $T$:

```{=tex}
\begin{align*}
\mathbb{E}[Y \mid X, W]=\theta(X) \mathbb{E}[T \mid X, W]+g(X, W)=\theta(X) h(X, W)+g(X, W)
\end{align*}
```

so

```{=tex}
\begin{align*}
Y_{\mathrm{res}}=Y-\mathbb{E}[Y \mid X, W]=\theta(X)(T-h(X, W))+v=\theta(X) T_{\mathrm{res}}+v
\end{align*}
```

Thus regressing $Y_{\mathrm{res}}$ on $T_{\mathrm{res}}$ recovers $\theta(X)$ up to noise.

In the on farm precision experiment (OFPE) setting, the ideas behind DML have shown promise for causal effect estimation. @kakimoto2022causal applied this framework to estimate heterogeneous treatment effects of nitrogen on yield, but their implementation was limited to a single-year experiment from one field and treated heterogeneity in a discrete way. They defined multiple “treatments” as increases from the lowest nitrogen rate to each higher rate, which is natural when there are only five or six fixed target rates per field. When data are pooled across fields with differing targets, however, applied nitrogen rates become effectively continuous, and the standard residualization of the treatment in DML does not extend cleanly to that setting.

Consider the continuous-treatment setting, where the structural model is

```{=tex}
\begin{align*}
Y=\theta(X, T)+g(X, W)+v
\end{align*}
```

with $T$ (e.g., nitrogen rate) continuous, and $X$ heterogeneity-inducing covariates that interact with $T$ through the flexible response function $\theta(X, T)$. In this case double-orthogonalization fails because $\theta$ is a general (nonlinear and interaction-rich) function of $T$. Residualizing the treatment by replacing $T$ with $T-\mathbb{E}[T \mid X, W]$ does not produce a valid adjustment for the heterogeneous effect. Formally,

```{=tex}
\begin{align*}
\theta(X, T)-\mathbb{E}[\theta(X, T) \mid X, W] \neq \theta(X, T-\mathbb{E}[T \mid X, W])
\end{align*}
```

and the clean decomposition that underlies double-orthogonalization in the linear-in-$T$ case breaks down. 
Instead, we apply single-orthogonalization (SO). We first estimate $f(X, W)=\mathbb{E}[Y \mid X, W]$ and form the residual $Y_{\mathrm{res}}=Y-f(X, W)$, and then recover $\theta(X, T)$ by flexibly modeling  $Y_{\mathrm{res}}$ as a function of $(X,T)$. This approach removes baseline variation due to $g(X,W)$ while preserving the full interaction structure between $X$ and the continuous treatment.

To study and compare these ideas systematically, we adopt a single underlying structural model and then implement alternative orthogonalization schemes.

The model of interest throughout is (Model 3)

```{=tex}
\begin{align*}
y = f(X, N) + g(W) + v
\end{align*}
```

where $y$ is crop yield, $N$ is the continuous nitrogen rate, $X$ is a set of covariates that induce heterogeneity in the impact of $N$ on $y$, and $W$ is a set of covariates that affect $y$ but do not interact with $N$. 
We implement three estimation strategies—double-orthogonalized, single-orthogonalized, and non-orthogonalized—that differ only in how (and whether) the outcome and treatment are residualized before the final fit. Orthogonalization means fitting a variable on its conditioning covariates and using the residual (observed minus predicted) so that the subsequent learner focuses on variation not explained by those covariates; all residualizations are performed with random forests. In the double-orthogonalized approach, both $y$ and $N$ are residualized with respect to $(X,W)$ and the final learner is trained on those residuals. In the single-orthogonalized approach, only $y$ is residualized and the raw $N$ is retained. The non-orthogonalized specification skips residualization entirely and fits the learner directly to $(y,N,X,W)$. For each strategy we consider three final-stage learners—neural networks (NN), random forests (RF), and causal forests (CF)—to evaluate how the orthogonalization scheme and learning algorithm interact in recovering heterogeneous nitrogen response.


The table below shows all the cases we consider.


```{r}
#| include: false
f_est <-
  data.table(
    "Approach Label" = c("DO-NN", "SO-RFF", "SO-NN", "DO-CF","NO-NN", "NO-RF"),
    "Approach Type" = c("Double-orthogonalized", "Single-orthogonalized", "Single-orthogonalized", "Double-orthogonalized", "Non-orthogonalized", "Non-orthogonalized"),
    "Y-orthogonalization" = c("Randome Forest", "Randome Forest", "Randome Forest", "Randome Forest", "NA", "NA"),
    "T-orthogonalization" = c("Randome Forest", "NA", "NA", "Randome Forest", "NA", "NA"),
    "Final stage" = c("Neural Network", "Random Forest", "Neural Network", "Causal Forest", "Neural Network", "Random Forest")
  ) %>%
  flextable() %>%
  fontsize(size = 16, part = "all") %>%
  autofit()

flextable::save_as_image(f_est, here::here("writing/f_est.png"), res = 300)
```

```{r}
#| echo: false
#| fig-width: 4
#| out-width: 4in
knitr::include_graphics(here::here("writing/f_est.png"))
```

### Single-orthogonalized NN (SO-NN) and (SO-RF)

In the single-orthogonalized framework only the baseline component $g(W)$ is partialed out before the final-stage estimation; the continuous treatment $N$ and heterogeneity-inducing covariates $X$ remain in their original form. Formally, starting from Model 3, we first estimate $g(W)=\mathbb{E}[y \mid W]$ using a cross-fitted random forest and form the residualized outcome

```{=tex}
\begin{align*}
\tilde{y}=y-\widehat{g}(W)
\end{align*}
```

The second stage fits a flexible model of $\tilde{y}$ on $(X,N)$ to recover the heterogeneous response function $f(X,N)$. The distinction between SO-NN and SO-RF is only in the choice of the final learner: SO-NN uses a neural network, while SO-RF uses a random forest. In both cases the learner estimates $\hat{f}(X, N)$, which is then used to predict yield under candidate nitrogen rates. Marginal profit is computed over a grid of $N$ values and the economically optimal nitrogen rate is selected as the one that maximizes 

```{=tex}
\begin{align*}
\widehat{\mathrm{EONR}}=\arg \max _N\left[P_{\text {Corn }} \times \hat{f}(X, N)-P_N \times N\right]
\end{align*}
```
where $P_{\text {Corn }}$ is the corn price, $P_{\text {N }}$ is the nitrogen price, and $\hat{f}$ is the estimated yield response.

### Double-orthogonalized CF (DO-CF) and ANN (DO-ANN) 

#### DO‑CF (continuous)

To adapt double-orthogonalization to the model of interest (Model 3), we estimate the heterogeneous response $f(X,N)$ by expanding the continuous treatment $N$ in a set of spline basis functions and allowing their coefficients to vary with the heterogeneity-inducing covariates $X$:

```{=tex}
\begin{align*}
y=\sum_{k=1}^K \theta_k(X) S_k(N)+g(X, W)+v
\end{align*}
```

Although double-orthogonalization generally fails when $f(X,N)$ is an arbitrary nonlinear function of $N$, this spline-based formulation restores the key linear-in-parameter structure that makes DO valid, because the model is linear in the transformed treatment basis $\left\{S_k(N)\right\}$. Residualizing each basis component and the outcome with respect to $(X,W)$ then yields a clean decomposition analogous to the linear-in-$T$ case. Let $\widetilde{S}_k(N)=S_k(N)-\mathbb{E}\left[S_k(N) \mid X, W\right]$. Then

```{=tex}
\begin{align*}
\tilde{y}=y-\mathbb{E}[y \mid X, W]=\sum_{k=1}^K \theta_k(X) \widetilde{S}_k(N)+v,
\end{align*}
```

so causal forest can nonparametrically estimate each heterogeneous weight $\theta_k(X)$  by relating the residualized outcome to the residualized spline bases. This Neyman-orthogonal (R-learner) style decomposition preserves the ability to capture complex, heterogeneous, and nonlinear treatment effects while inheriting the robustness of double-orthogonalization: small errors in the nuisance fits for $g(X,W)$ or the conditional means of the bases do not induce first-order bias in $\theta_k(X)$. The estimated $\theta_k(X)$ then combine to recover the full heterogeneous response function and, by differencing across candidate $N$ values, site-specific treatment effects and economically optimal nitrogen rates.

#### DO‑ANN

In the DO-ANN approach, we apply double-orthogonalization to Model 3 by residualizing both the outcome $y$ and the continuous treatment $N$ with respect to $(X, W)$ using cross-fitted random forests:

```{=tex}
\tilde{y}=y-\widehat{\mathbb{E}}[y \mid X, W], \quad \tilde{N}=N-\widehat{\mathbb{E}}[N \mid X, W]
\end{align*}
```

The final-stage learner is a neural network that models $\tilde{y}$ as a linear function of $\tilde{N}$, with heterogeneity in the slope captured by covariates $X$:

```{=tex}
\hat{\tilde{y}}=\hat{\theta}(X) \cdot \tilde{N}
\end{align*}
```

This structure preserves the linear-in-treatment-residual form required for valid double-orthogonalization while allowing $\hat{\theta}(X)$ to vary flexibly across sites. The neural network receives $X$ as input and outputs the site-specific treatment effect.

After training, we reconstruct $\hat{f}(X, N)$ over a grid of candidate nitrogen rates by evaluating the model across values of $N$, and select the economically optimal nitrogen rate.

### Non-orthogonalized ANN (NO-NN) and RF (NO-RF)

In the non‑orthogonalized setting, neither the outcome variable nor the treatment is residualized prior to estimation. Instead, the model directly fits the observed yield on both the nitrogen rate and covariates. We estimate the response function $\hat{Y}=\hat{f}(X, N)$ using the original values of $Y$, $N$ and $X$, without any orthogonalization. As in the single‑orthogonalized approaches, the function $\hat{f}(X, N)$ is estimated non‑parametrically. The difference between NO‑NN and NO‑RF lies in the choice of final-stage learner: NO‑NN uses a neural network, while NO‑RF relies on a random forest. Once the yield response function is estimated, the EONR is determined using the same profit-maximization procedure described in earlier models.


## Performance Measurement

For each simulation round, we evaluate model performance by calculating the root mean squared error (RMSE) of EONR predictions and the associated profit loss for each method. The RMSE of EONR predictions in a given simulation round is computed as follows:


```{=tex}
\begin{align*}
RMSE_{EONR}=\sqrt{\frac{1}{n} \sum_{i=1}^n\left(\widehat{EONR}_i-EONR_i\right)^2}
\end{align*}
```

To assess the predictive accuracy and economic relevance of these modeling approaches, we design a set of simulation experiments that reflect realistic agronomic conditions. These simulations serve as a controlled environment for evaluating model performance in estimating yield response functions and recommending optimal nitrogen rates.

## Simulation Scenarios

To evaluate the performance of the proposed models we design Monte Carlo simulations that mimic a typical on-farm precision experimentation (OFPE) setting. These simulations examine the ability of each method to accurately estimate the site-specific yield response to nitrogen application and the EONR under varying data availability conditions.

Our simulation consists of 500 independently generated fields, each representing a distinct agronomic environment with field-specific parameters that shape the crop’s response to nitrogen application. These parameters vary systematically across fields to introduce heterogeneity in yield responses. The true yield response in each field follows a quadratic-plateau functional form, a widely used structure for modeling nitrogen response curves in agronomic studies.

For each simulation round, one field is selected as the test field. The remaining fields are used to construct the training set in three scenarios: (1) one-field training, (2) five-field training, and (3) ten-field training. These scenarios allow us to assess how model performance changes with the size and diversity of training data. Within each round, the model is trained on the designated number of training fields and then used to estimate the yield response function and the site-specific EONR for the test field.

The experimental design within each field consists of randomized nitrogen treatment rates applied across plots. The nitrogen rates vary between fields and are drawn to reflect realistic trial setups that span a range of agronomic optima. For evaluation purposes, we use a grid of candidate nitrogen rates to compute predicted yield and associated marginal profit for each observation. The predicted EONR is the nitrogen rate that maximizes predicted profit.

# Results and Discussions


# Conclusion




